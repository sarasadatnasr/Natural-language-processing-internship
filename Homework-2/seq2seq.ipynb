{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.3.0)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "    \n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('./%s-%s.txt' % (lang1, lang2), encoding='latin-1').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 11119 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "sort 2917\n",
      "jumble 2920\n",
      "['this probably young you re too to understand .', 'you re probably too young to understand this .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('jumble', 'sort', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('jumbled sentence : ', pair[0])\n",
    "        print('sorted sentence : ', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('prediction :', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 33s (- 83m 40s) (500 0%) 3.5774\n",
      "1m 9s (- 86m 6s) (1000 1%) 2.9893\n",
      "1m 46s (- 86m 59s) (1500 2%) 2.8075\n",
      "2m 22s (- 86m 31s) (2000 2%) 2.8174\n",
      "2m 59s (- 86m 43s) (2500 3%) 2.5720\n",
      "3m 39s (- 87m 53s) (3000 4%) 2.3962\n",
      "4m 19s (- 88m 13s) (3500 4%) 2.3463\n",
      "5m 0s (- 88m 50s) (4000 5%) 2.3128\n",
      "5m 40s (- 88m 53s) (4500 6%) 2.3191\n",
      "6m 16s (- 87m 55s) (5000 6%) 2.1349\n",
      "6m 47s (- 85m 50s) (5500 7%) 2.0703\n",
      "7m 17s (- 83m 55s) (6000 8%) 1.9586\n",
      "7m 49s (- 82m 25s) (6500 8%) 2.0612\n",
      "8m 20s (- 81m 3s) (7000 9%) 1.9715\n",
      "8m 51s (- 79m 46s) (7500 10%) 1.9044\n",
      "9m 22s (- 78m 33s) (8000 10%) 1.8008\n",
      "9m 53s (- 77m 24s) (8500 11%) 1.7229\n",
      "10m 25s (- 76m 24s) (9000 12%) 1.7169\n",
      "10m 56s (- 75m 25s) (9500 12%) 1.7166\n",
      "11m 28s (- 74m 34s) (10000 13%) 1.6855\n",
      "11m 59s (- 73m 38s) (10500 14%) 1.4975\n",
      "12m 29s (- 72m 41s) (11000 14%) 1.5088\n",
      "13m 0s (- 71m 48s) (11500 15%) 1.5439\n",
      "13m 30s (- 70m 57s) (12000 16%) 1.5555\n",
      "14m 1s (- 70m 8s) (12500 16%) 1.4628\n",
      "14m 33s (- 69m 25s) (13000 17%) 1.4081\n",
      "15m 5s (- 68m 46s) (13500 18%) 1.4970\n",
      "15m 37s (- 68m 5s) (14000 18%) 1.3180\n",
      "16m 9s (- 67m 26s) (14500 19%) 1.2847\n",
      "16m 42s (- 66m 48s) (15000 20%) 1.3887\n",
      "17m 14s (- 66m 11s) (15500 20%) 1.2431\n",
      "17m 53s (- 65m 59s) (16000 21%) 1.3599\n",
      "18m 22s (- 65m 8s) (16500 22%) 1.2503\n",
      "18m 47s (- 64m 8s) (17000 22%) 1.2885\n",
      "19m 13s (- 63m 10s) (17500 23%) 1.1395\n",
      "19m 39s (- 62m 16s) (18000 24%) 1.1882\n",
      "20m 4s (- 61m 19s) (18500 24%) 1.0796\n",
      "20m 30s (- 60m 26s) (19000 25%) 1.1775\n",
      "20m 55s (- 59m 34s) (19500 26%) 1.1292\n",
      "21m 21s (- 58m 43s) (20000 26%) 1.0638\n",
      "21m 47s (- 57m 54s) (20500 27%) 1.0361\n",
      "22m 13s (- 57m 7s) (21000 28%) 1.0477\n",
      "22m 38s (- 56m 21s) (21500 28%) 1.0263\n",
      "23m 3s (- 55m 34s) (22000 29%) 1.0131\n",
      "23m 29s (- 54m 48s) (22500 30%) 1.0677\n",
      "23m 54s (- 54m 3s) (23000 30%) 0.9486\n",
      "24m 19s (- 53m 18s) (23500 31%) 0.9673\n",
      "24m 44s (- 52m 34s) (24000 32%) 0.9229\n",
      "25m 9s (- 51m 52s) (24500 32%) 0.9553\n",
      "25m 35s (- 51m 10s) (25000 33%) 0.9272\n",
      "26m 0s (- 50m 29s) (25500 34%) 0.9292\n",
      "26m 25s (- 49m 48s) (26000 34%) 0.8867\n",
      "26m 50s (- 49m 7s) (26500 35%) 0.8458\n",
      "27m 16s (- 48m 28s) (27000 36%) 0.8851\n",
      "27m 41s (- 47m 49s) (27500 36%) 0.8757\n",
      "28m 6s (- 47m 10s) (28000 37%) 0.8034\n",
      "28m 31s (- 46m 32s) (28500 38%) 0.7439\n",
      "28m 58s (- 45m 57s) (29000 38%) 0.7853\n",
      "29m 23s (- 45m 19s) (29500 39%) 0.7856\n",
      "29m 49s (- 44m 43s) (30000 40%) 0.7426\n",
      "30m 15s (- 44m 8s) (30500 40%) 0.7443\n",
      "30m 42s (- 43m 34s) (31000 41%) 0.7198\n",
      "31m 8s (- 43m 0s) (31500 42%) 0.6684\n",
      "31m 39s (- 42m 32s) (32000 42%) 0.6272\n",
      "32m 23s (- 42m 21s) (32500 43%) 0.7467\n",
      "33m 6s (- 42m 8s) (33000 44%) 0.6932\n",
      "33m 57s (- 42m 3s) (33500 44%) 0.6491\n",
      "34m 42s (- 41m 50s) (34000 45%) 0.7338\n",
      "35m 26s (- 41m 35s) (34500 46%) 0.6457\n",
      "36m 4s (- 41m 13s) (35000 46%) 0.7449\n",
      "36m 43s (- 40m 51s) (35500 47%) 0.6509\n",
      "37m 20s (- 40m 26s) (36000 48%) 0.6121\n",
      "37m 54s (- 39m 58s) (36500 48%) 0.6159\n",
      "38m 31s (- 39m 34s) (37000 49%) 0.6304\n",
      "39m 9s (- 39m 9s) (37500 50%) 0.5905\n",
      "39m 48s (- 38m 45s) (38000 50%) 0.6523\n",
      "40m 23s (- 38m 17s) (38500 51%) 0.5812\n",
      "40m 59s (- 37m 50s) (39000 52%) 0.5652\n",
      "41m 34s (- 37m 22s) (39500 52%) 0.5738\n",
      "42m 11s (- 36m 54s) (40000 53%) 0.5186\n",
      "42m 45s (- 36m 25s) (40500 54%) 0.5383\n",
      "43m 18s (- 35m 54s) (41000 54%) 0.6007\n",
      "43m 46s (- 35m 20s) (41500 55%) 0.4917\n",
      "44m 23s (- 34m 52s) (42000 56%) 0.4764\n",
      "44m 57s (- 34m 23s) (42500 56%) 0.5061\n",
      "45m 35s (- 33m 55s) (43000 57%) 0.5168\n",
      "46m 9s (- 33m 25s) (43500 57%) 0.5254\n",
      "46m 43s (- 32m 55s) (44000 58%) 0.4753\n",
      "47m 18s (- 32m 25s) (44500 59%) 0.4832\n",
      "47m 51s (- 31m 54s) (45000 60%) 0.4955\n",
      "48m 32s (- 31m 28s) (45500 60%) 0.5172\n",
      "49m 6s (- 30m 57s) (46000 61%) 0.5082\n",
      "49m 40s (- 30m 26s) (46500 62%) 0.4607\n",
      "50m 13s (- 29m 55s) (47000 62%) 0.4348\n",
      "50m 47s (- 29m 24s) (47500 63%) 0.4386\n",
      "51m 21s (- 28m 53s) (48000 64%) 0.4440\n",
      "51m 55s (- 28m 22s) (48500 64%) 0.4539\n",
      "52m 28s (- 27m 50s) (49000 65%) 0.4170\n",
      "53m 1s (- 27m 19s) (49500 66%) 0.3971\n",
      "53m 35s (- 26m 47s) (50000 66%) 0.3930\n",
      "54m 8s (- 26m 16s) (50500 67%) 0.3779\n",
      "54m 41s (- 25m 44s) (51000 68%) 0.3212\n",
      "55m 14s (- 25m 12s) (51500 68%) 0.4137\n",
      "55m 45s (- 24m 39s) (52000 69%) 0.4433\n",
      "56m 20s (- 24m 8s) (52500 70%) 0.4174\n",
      "56m 54s (- 23m 37s) (53000 70%) 0.4048\n",
      "57m 27s (- 23m 5s) (53500 71%) 0.4069\n",
      "58m 0s (- 22m 33s) (54000 72%) 0.3351\n",
      "58m 33s (- 22m 1s) (54500 72%) 0.3602\n",
      "59m 8s (- 21m 30s) (55000 73%) 0.3481\n",
      "59m 40s (- 20m 58s) (55500 74%) 0.3449\n",
      "60m 14s (- 20m 26s) (56000 74%) 0.3172\n",
      "60m 48s (- 19m 54s) (56500 75%) 0.3772\n",
      "61m 21s (- 19m 22s) (57000 76%) 0.4064\n",
      "61m 55s (- 18m 50s) (57500 76%) 0.3825\n",
      "62m 28s (- 18m 18s) (58000 77%) 0.3811\n",
      "63m 2s (- 17m 46s) (58500 78%) 0.3160\n",
      "63m 34s (- 17m 14s) (59000 78%) 0.3268\n",
      "64m 7s (- 16m 42s) (59500 79%) 0.3131\n",
      "64m 39s (- 16m 9s) (60000 80%) 0.2823\n",
      "65m 11s (- 15m 37s) (60500 80%) 0.3581\n",
      "65m 45s (- 15m 5s) (61000 81%) 0.2894\n",
      "66m 18s (- 14m 33s) (61500 82%) 0.2900\n",
      "66m 50s (- 14m 0s) (62000 82%) 0.2761\n",
      "67m 22s (- 13m 28s) (62500 83%) 0.2718\n",
      "67m 55s (- 12m 56s) (63000 84%) 0.2941\n",
      "68m 27s (- 12m 23s) (63500 84%) 0.3028\n",
      "68m 59s (- 11m 51s) (64000 85%) 0.3009\n",
      "69m 30s (- 11m 18s) (64500 86%) 0.2814\n",
      "70m 2s (- 10m 46s) (65000 86%) 0.2675\n",
      "70m 34s (- 10m 14s) (65500 87%) 0.3315\n",
      "71m 5s (- 9m 41s) (66000 88%) 0.2860\n",
      "71m 37s (- 9m 9s) (66500 88%) 0.2847\n",
      "72m 10s (- 8m 37s) (67000 89%) 0.2764\n",
      "72m 41s (- 8m 4s) (67500 90%) 0.2634\n",
      "73m 14s (- 7m 32s) (68000 90%) 0.2440\n",
      "73m 45s (- 6m 59s) (68500 91%) 0.2648\n",
      "74m 18s (- 6m 27s) (69000 92%) 0.2521\n",
      "74m 50s (- 5m 55s) (69500 92%) 0.2515\n",
      "75m 23s (- 5m 23s) (70000 93%) 0.2778\n",
      "75m 56s (- 4m 50s) (70500 94%) 0.2277\n",
      "76m 29s (- 4m 18s) (71000 94%) 0.2312\n",
      "77m 3s (- 3m 46s) (71500 95%) 0.2236\n",
      "77m 35s (- 3m 13s) (72000 96%) 0.2514\n",
      "78m 2s (- 2m 41s) (72500 96%) 0.2525\n",
      "78m 26s (- 2m 8s) (73000 97%) 0.2295\n",
      "78m 51s (- 1m 36s) (73500 98%) 0.1948\n",
      "79m 17s (- 1m 4s) (74000 98%) 0.2497\n",
      "79m 42s (- 0m 32s) (74500 99%) 0.2327\n",
      "80m 7s (- 0m 0s) (75000 100%) 0.1901\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jumbled sentence :  father to be old . enough he her s\n",
      "sorted sentence :  he s old enough to be her father .\n",
      "prediction : he s old enough to be her father . <EOS>\n",
      "\n",
      "jumbled sentence :  am i . all ears\n",
      "sorted sentence :  i am all ears .\n",
      "prediction : i am all afraid i . . <EOS>\n",
      "\n",
      "jumbled sentence :  great is a known as painter he .\n",
      "sorted sentence :  he is known as a great painter .\n",
      "prediction : he is a known as great painter . . <EOS>\n",
      "\n",
      "jumbled sentence :  to going help i need . your m\n",
      "sorted sentence :  i m going to need your help .\n",
      "prediction : i m going to need your help . <EOS>\n",
      "\n",
      "jumbled sentence :  i . it night a call m going to\n",
      "sorted sentence :  i m going to call it a night .\n",
      "prediction : i m going to call it a night . <EOS>\n",
      "\n",
      "jumbled sentence :   . re you unambitious\n",
      "sorted sentence :  you re unambitious .\n",
      "prediction : you re unambitious silly . <EOS>\n",
      "\n",
      "jumbled sentence :   . we are to baby have a going\n",
      "sorted sentence :  we are going to have a baby .\n",
      "prediction : we are going to have a baby . <EOS>\n",
      "\n",
      "jumbled sentence :  machine she s the fixing .\n",
      "sorted sentence :  she s fixing the machine .\n",
      "prediction : she s fixing the the machine . <EOS>\n",
      "\n",
      "jumbled sentence :   s . singer she well as a known\n",
      "sorted sentence :  she s well known as a singer .\n",
      "prediction : she s well known as a singer . <EOS>\n",
      "\n",
      "jumbled sentence :  fun kind of re they .\n",
      "sorted sentence :  they re kind of fun .\n",
      "prediction : they re kind of fun of fun . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15e83610f10>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_words, attentions = evaluate(\n",
    "    encoder1, attn_decoder1, \"she is likely to come .\")\n",
    "plt.matshow(attentions.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afb734500600fd355917ca529030176ea0ca205570884b88f2f6f7d791fd3fbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

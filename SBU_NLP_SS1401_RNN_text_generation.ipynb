{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0BjCLil_9Vo"
      },
      "source": [
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/6/6a/Sbu-logo.svg/1200px-Sbu-logo.svg.png\" alt=\"keras\" width=\"150\" height=\"150\">\n",
        "\n",
        "<h1 align=center><font size = 7>NLP Summer School</font></h1>\n",
        "<h1 align=center><font size = 6>NLP Research Lab</font></h1>\n",
        "<h1 align=center><font size = 5>Shahid Beheshti University</font></h1>\n",
        "<h1 align=center><font size = 4> July 2022 </font></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgx223ro_9Vu"
      },
      "source": [
        "### Original Repo\n",
        "https://www.kaggle.com/code/ab971631/beginners-guide-to-text-generation-pytorch/notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_jg5ioBide1"
      },
      "source": [
        "**Import the libraries**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "RNN_text_generation:\n",
        "استفاده از بافتار از 2 کلمه به 6 کلمه ارتقاء پیدا کند (20)\n",
        "استفاده از روشهای بارگذاری داده متنی (کلاس دیتاست و دیتالودر در پایتورچ) (امتیازی) (10)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "M4cL0tcxClYi",
        "outputId": "c9d2813f-25f8-4675-fa5a-487637c8f83d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nRNN_text_generation:\\nاستفاده از بافتار از 2 کلمه به 6 کلمه ارتقاء پیدا کند (20)\\nاستفاده از روشهای بارگذاری داده متنی (کلاس دیتاست و دیتالودر در پایتورچ) (امتیازی) (10)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_JUjWgepi9Y1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "a6ccb765-22c1-40d5-f8a0-93528916b14e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchdata\n",
            "  Downloading torchdata-0.4.0-cp37-cp37m-manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchdata) (2.23.0)\n",
            "Requirement already satisfied: torch==1.12.0 in /usr/local/lib/python3.7/dist-packages (from torchdata) (1.12.0+cu113)\n",
            "Collecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n",
            "Collecting urllib3>=1.25\n",
            "  Downloading urllib3-1.26.10-py2.py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 71.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.12.0->torchdata) (4.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2.10)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 67.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (3.0.4)\n",
            "Installing collected packages: urllib3, portalocker, torchdata\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed portalocker-2.5.1 torchdata-0.4.0 urllib3-1.25.11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install unidecode -q\n",
        "!pip install hazm -q\n",
        "!pip install torchdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgckTxH__9V2"
      },
      "source": [
        "Who wants to add something about the Linux directives we can exploit?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2022-07-14T16:01:42.621790Z",
          "iopub.status.busy": "2022-07-14T16:01:42.621498Z",
          "iopub.status.idle": "2022-07-14T16:01:45.424397Z",
          "shell.execute_reply": "2022-07-14T16:01:45.423686Z",
          "shell.execute_reply.started": "2022-07-14T16:01:42.621740Z"
        },
        "id": "vQ3-bxXaide2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import string\n",
        "import unidecode\n",
        "import random\n",
        "import torch\n",
        "from hazm import stopwords_list\n",
        "from hazm import Lemmatizer\n",
        "from tqdm import tqdm\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-07-14T16:01:45.426061Z",
          "iopub.status.busy": "2022-07-14T16:01:45.425772Z",
          "iopub.status.idle": "2022-07-14T16:01:45.505366Z",
          "shell.execute_reply": "2022-07-14T16:01:45.504265Z",
          "shell.execute_reply.started": "2022-07-14T16:01:45.426016Z"
        },
        "id": "EKHWK0K1ide3",
        "outputId": "e0e152df-4547-4782-cac8-60040b776f53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on GPU!\n"
          ]
        }
      ],
      "source": [
        "# Check if GPU is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "if(train_on_gpu):\n",
        "    print('Training on GPU!')\n",
        "else: \n",
        "    print('No GPU available, training on CPU; consider making n_epochs very small.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6h5P9Dbide4"
      },
      "source": [
        "**Load the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "execution": {
          "iopub.execute_input": "2022-07-14T16:05:20.171365Z",
          "iopub.status.busy": "2022-07-14T16:05:20.171089Z",
          "iopub.status.idle": "2022-07-14T16:05:20.280324Z",
          "shell.execute_reply": "2022-07-14T16:05:20.279689Z",
          "shell.execute_reply.started": "2022-07-14T16:05:20.171316Z"
        },
        "id": "2l5EPpoRide6"
      },
      "outputs": [],
      "source": [
        "path = './voa_fa_2003-2008_orig.txt'\n",
        "with open(path, 'r', encoding='utf-8') as f:\n",
        "    text = ' '.join([line.strip() for line in f.readlines() if not line.startswith('#')])\n",
        "    text = text.split('.')\n",
        "    text = random.sample(text, 150)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the required libraries\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# defining the Dataset class\n",
        "class data_set(Dataset):\n",
        "\tdef __init__(self):\n",
        "\t\tnumbers = list(range(0, 100, 1))\n",
        "\t\tself.data = numbers\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.data)\n",
        "\n",
        "\tdef __getitem__(self, index):\n",
        "\t\treturn self.data[index]\n",
        "\n",
        "\n",
        "dataset = data_set()\n",
        "\n",
        "# implementing dataloader on the dataset and printing per batch\n",
        "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
        "for i, batch in enumerate(dataloader):\n",
        "\tprint(i, batch)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Vb65B0QCxaR",
        "outputId": "959e9a28-8caf-4c9a-a4ae-fdffced1dba3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 tensor([21,  3, 60, 35, 36,  9, 25, 29, 73, 70])\n",
            "1 tensor([98,  1, 17, 65, 13, 76, 50, 87, 79, 24])\n",
            "2 tensor([69, 51, 53, 22, 61, 26, 37, 71, 55, 74])\n",
            "3 tensor([97, 66, 91, 14, 68,  0, 82, 11, 92, 72])\n",
            "4 tensor([19, 99, 94, 47, 90, 78, 10, 20, 42, 83])\n",
            "5 tensor([15, 81, 52, 41, 16, 59, 18, 85, 48, 45])\n",
            "6 tensor([56, 44, 27,  6, 80, 75, 63, 58, 57, 31])\n",
            "7 tensor([67, 46, 96, 43, 23, 62,  5,  4, 95,  2])\n",
            "8 tensor([88, 28, 39, 54,  8, 34, 30, 89, 32,  7])\n",
            "9 tensor([93, 86, 64, 84, 77, 12, 40, 38, 49, 33])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Im9zMXqide7"
      },
      "source": [
        "**Dataset cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-07-14T16:05:24.186912Z",
          "iopub.status.busy": "2022-07-14T16:05:24.186638Z",
          "iopub.status.idle": "2022-07-14T16:05:24.197476Z",
          "shell.execute_reply": "2022-07-14T16:05:24.196849Z",
          "shell.execute_reply.started": "2022-07-14T16:05:24.186864Z"
        },
        "id": "dwQBA4BMide8",
        "outputId": "4bbbc921-fde8-413d-ed44-31c14d34fe10"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4018"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "def joinStrings(text):\n",
        "    return ' '.join(string for string in text)\n",
        "text = joinStrings(text)\n",
        "len(text.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-14T16:05:27.193997Z",
          "iopub.status.busy": "2022-07-14T16:05:27.193708Z",
          "iopub.status.idle": "2022-07-14T16:05:29.145556Z",
          "shell.execute_reply": "2022-07-14T16:05:29.144854Z",
          "shell.execute_reply.started": "2022-07-14T16:05:27.193946Z"
        },
        "id": "7u0DkdhTide8"
      },
      "outputs": [],
      "source": [
        "\n",
        "stop = set(stopwords_list())\n",
        "exclude = set(string.punctuation) \n",
        "lemma = lemmatizer = Lemmatizer()\n",
        "def clean(doc):\n",
        "        stop_free = \" \".join([i for i in doc.split() if i not in stop])\n",
        "        punc_free = \"\".join(ch for ch in stop_free if ch not in exclude)\n",
        "        # normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
        "        return punc_free\n",
        "test_sentence = clean(text).lower().split()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErLa0Vhmide9"
      },
      "source": [
        "> **N-Gram Language Modeling**\n",
        "\n",
        "Recall that in an n-gram language model, given a sequence of words w, we want to compute.\n",
        "                                      * P(wi|wi−1,wi−2,…,wi−n+1)                                                     \n",
        "Where wi is the ith word of the sequence.                                                                              here we will take n=2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-07-14T16:05:54.842133Z",
          "iopub.status.busy": "2022-07-14T16:05:54.841866Z",
          "iopub.status.idle": "2022-07-14T16:05:54.848595Z",
          "shell.execute_reply": "2022-07-14T16:05:54.847514Z",
          "shell.execute_reply.started": "2022-07-14T16:05:54.842088Z"
        },
        "id": "UOzsTkO9ide-",
        "outputId": "ebd7a2af-0ff0-4341-96ed-9d16325e113b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['مقامات،', 'بنظر'], 'ميرسد'), (['بنظر', 'ميرسد'], 'اين'), (['ميرسد', 'اين'], 'انفجارهائی'), (['اين', 'انفجارهائی'], 'هفته'), (['انفجارهائی', 'هفته'], 'گذشته'), (['هفته', 'گذشته'], 'ماه')]\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "trigrams = [([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2])\n",
        "            for i in range(len(test_sentence) - 2)]\n",
        "chunk_len=len(trigrams)\n",
        "print(trigrams[:6])\n",
        "'''\n",
        "\n",
        "#The use of context should be improved from 2 words to 6 words (20)\n",
        "sevengrams = [([test_sentence[i], test_sentence[i + 1],\n",
        "                test_sentence[i + 2], test_sentence[i + 3],test_sentence[i + 4],\n",
        "                test_sentence[i + 5]],test_sentence[i + 6])\n",
        "               \n",
        "            for i in range(len(test_sentence) - 6)]\n",
        "chunk_len=len(sevengrams)\n",
        "print(sevengrams[:6])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding more context! "
      ],
      "metadata": {
        "id": "ioAB7yjSCvpo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-14T16:06:01.296981Z",
          "iopub.status.busy": "2022-07-14T16:06:01.296712Z",
          "iopub.status.idle": "2022-07-14T16:06:01.301791Z",
          "shell.execute_reply": "2022-07-14T16:06:01.300553Z",
          "shell.execute_reply.started": "2022-07-14T16:06:01.296934Z"
        },
        "id": "RG6CU-h9ide-"
      },
      "outputs": [],
      "source": [
        "vocab = set(test_sentence)\n",
        "voc_len=len(vocab)\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CU0mB6JkmgIJ",
        "outputId": "b8d2ff19-ed02-48e1-f830-eeb196836d4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1576"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-14T16:06:02.412874Z",
          "iopub.status.busy": "2022-07-14T16:06:02.412600Z",
          "iopub.status.idle": "2022-07-14T16:06:02.437505Z",
          "shell.execute_reply": "2022-07-14T16:06:02.436920Z",
          "shell.execute_reply.started": "2022-07-14T16:06:02.412828Z"
        },
        "id": "qyhIn8qride_"
      },
      "outputs": [],
      "source": [
        "inp=[]\n",
        "tar=[]\n",
        "for context, target in trigrams:\n",
        "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
        "        inp.append(context_idxs)\n",
        "        targ = torch.tensor([word_to_ix[target]], dtype=torch.long)\n",
        "        tar.append(targ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2r2K3fmide_"
      },
      "source": [
        "**RNN model for Text Generation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-14T16:06:38.686648Z",
          "iopub.status.busy": "2022-07-14T16:06:38.686358Z",
          "iopub.status.idle": "2022-07-14T16:06:38.693884Z",
          "shell.execute_reply": "2022-07-14T16:06:38.693124Z",
          "shell.execute_reply.started": "2022-07-14T16:06:38.686592Z"
        },
        "id": "10CnMxKYide_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
        "        self.rnn = nn.RNN(hidden_size*2, hidden_size, n_layers, batch_first=True,\n",
        "                          bidirectional=False)\n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    def forward(self, input, hidden):\n",
        "        input = self.encoder(input.view(1, -1))\n",
        "        output, hidden = self.rnn(input.view(1, 1, -1), hidden)\n",
        "        output = self.decoder(output.view(1, -1))\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How embedding layer works?\n"
      ],
      "metadata": {
        "id": "plJh4TPSDA4-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-14T16:06:51.567699Z",
          "iopub.status.busy": "2022-07-14T16:06:51.567394Z",
          "iopub.status.idle": "2022-07-14T16:06:51.573095Z",
          "shell.execute_reply": "2022-07-14T16:06:51.572219Z",
          "shell.execute_reply.started": "2022-07-14T16:06:51.567639Z"
        },
        "id": "9b58aVYridfA"
      },
      "outputs": [],
      "source": [
        "def train(inp, target):\n",
        "    hidden = decoder.init_hidden().cuda()\n",
        "    decoder.zero_grad()\n",
        "    loss = 0\n",
        "    \n",
        "    for c in range(chunk_len):\n",
        "        output, hidden = decoder(inp[c].cuda(), hidden)\n",
        "        loss += criterion(output, target[c].cuda())\n",
        "\n",
        "    loss.backward()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.data.item() / chunk_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-14T16:06:59.286401Z",
          "iopub.status.busy": "2022-07-14T16:06:59.286089Z",
          "iopub.status.idle": "2022-07-14T16:06:59.291879Z",
          "shell.execute_reply": "2022-07-14T16:06:59.290777Z",
          "shell.execute_reply.started": "2022-07-14T16:06:59.286350Z"
        },
        "id": "qfHCE3O1idfA"
      },
      "outputs": [],
      "source": [
        "import time, math\n",
        "\n",
        "def time_since(since):\n",
        "    s = time.time() - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-07-14T16:07:10.182881Z",
          "iopub.status.busy": "2022-07-14T16:07:10.182538Z",
          "iopub.status.idle": "2022-07-14T16:13:34.683169Z",
          "shell.execute_reply": "2022-07-14T16:13:34.682353Z",
          "shell.execute_reply.started": "2022-07-14T16:07:10.182830Z"
        },
        "id": "y2rCSK4TidfB",
        "outputId": "bdfd8b0d-2e50-4bfd-bca3-e4edd6794d2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training ...: 100%|██████████| 300/300 [08:55<00:00,  1.79s/it]\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 300\n",
        "print_every = 100\n",
        "plot_every = 10\n",
        "hidden_size = 100\n",
        "n_layers = 1\n",
        "lr = 0.015\n",
        "\n",
        "decoder = RNN(voc_len, hidden_size, voc_len, n_layers)\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0\n",
        "if(train_on_gpu):\n",
        "    decoder.cuda()\n",
        "for _, epoch in tqdm(enumerate(range(1, n_epochs + 1)), desc='Training ...', total=n_epochs):\n",
        "    loss = train(inp,tar)       \n",
        "    loss_avg += loss\n",
        "\n",
        "\n",
        "    if epoch % plot_every == 0:\n",
        "        all_losses.append(loss_avg / plot_every)\n",
        "        loss_avg = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "execution": {
          "iopub.execute_input": "2022-07-14T16:25:09.686546Z",
          "iopub.status.busy": "2022-07-14T16:25:09.686237Z",
          "iopub.status.idle": "2022-07-14T16:25:09.952465Z",
          "shell.execute_reply": "2022-07-14T16:25:09.951654Z",
          "shell.execute_reply.started": "2022-07-14T16:25:09.686479Z"
        },
        "id": "T1FaSEYvidfB",
        "outputId": "614f0e2d-a67d-44cb-98ef-b8ee66dcdbcd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe1028a8a50>]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "%matplotlib inline\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(all_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfHx_oPEidfC"
      },
      "source": [
        "**Generating the text**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-14T16:25:58.375749Z",
          "iopub.status.busy": "2022-07-14T16:25:58.375451Z",
          "iopub.status.idle": "2022-07-14T16:25:58.382305Z",
          "shell.execute_reply": "2022-07-14T16:25:58.381437Z",
          "shell.execute_reply.started": "2022-07-14T16:25:58.375698Z"
        },
        "id": "qfZFqxCGidfC"
      },
      "outputs": [],
      "source": [
        "def evaluate(prime_str='this process', predict_len=100, temperature=0.8):\n",
        "    hidden = decoder.init_hidden().cuda()\n",
        "    for p in range(predict_len):\n",
        "        \n",
        "        prime_input = torch.tensor([word_to_ix[w] for w in prime_str.split()], dtype=torch.long).cuda()\n",
        "        # print(prime_input)\n",
        "        inp = prime_input[-2:] #last two words as input\n",
        "        output, hidden = decoder(inp, hidden)\n",
        "        \n",
        "        # Sample from the network as a multinomial distribution\n",
        "        output_dist = output.data.view(-1).div(temperature).exp()\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "        \n",
        "        # Add predicted word to string and use as next input\n",
        "        predicted_word = list(word_to_ix.keys())[list(word_to_ix.values()).index(top_i)]\n",
        "        prime_str += \" \" + predicted_word\n",
        "#         inp = torch.tensor(word_to_ix[predicted_word], dtype=torch.long)\n",
        "\n",
        "    return prime_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-07-14T16:26:00.250826Z",
          "iopub.status.busy": "2022-07-14T16:26:00.250522Z",
          "iopub.status.idle": "2022-07-14T16:26:00.750120Z",
          "shell.execute_reply": "2022-07-14T16:26:00.749344Z",
          "shell.execute_reply.started": "2022-07-14T16:26:00.250773Z"
        },
        "id": "KpL4WJ7VidfC",
        "outputId": "197071e4-145c-49d1-915c-d849552c864d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "اين بنظر ميرسد اين انفجارهائی هفته گذشته ماه مارس کازابلانکا رخ داد، مشارکت اين سياستها جامعه جهانی همخوانی برقراری روابط مثبت ميان مردم ايران مردم آمريکاو کشورهای ديگر جهان مانع ايجاد ميکند جمهوری خواهان کنگره هفته گذشته موفق تصويب لايحه مشابهی مجلس\n"
          ]
        }
      ],
      "source": [
        "startwith = 'اين بنظر'\n",
        "print(evaluate(startwith, 40, temperature=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How temperature parameter relates to the random parameter in the N-gram example?"
      ],
      "metadata": {
        "id": "idJbiRYNE883"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_i5b8TUUE9cT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SBU_NLP_SS1401_RNN_text_generation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}